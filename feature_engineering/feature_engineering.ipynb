{"cells":[{"cell_type":"markdown","metadata":{"id":"9986000b"},"source":["# Model Selection and Rationale\n","\n","## Models Used in This Analysis:\n","\n","### 1. Logistic Regression\n","- Purpose: Predicts probability of categorical outcomes\n","- Why chosen:\n","  - Excellent interpretability of feature importance\n","  - Efficient with limited computational resources\n","  - Provides probability scores for predictions\n","  - Works well when decision boundaries are roughly linear\n","  - Fast training and inference times\n","\n","### 2. Random Forest Classifier\n","- Purpose: Ensemble learning method for classification\n","- Why chosen:\n","  - Handles non-linear relationships effectively\n","  - Robust against overfitting\n","  - Captures complex interactions between features\n","  - Provides feature importance rankings\n","  - Performs well with both numerical and categorical data\n","\n","## Why Use Both Models?\n","1. Complementary Strengths:\n","   - Logistic Regression: Linear patterns and interpretability\n","   - Random Forest: Complex patterns and robustness\n","\n","2. Model Comparison:\n","   - Validates if complexity adds value\n","   - Provides different perspectives on feature importance\n","\n","3. Business Value:\n","   - Logistic Regression: Quick insights and easy deployment\n","   - Random Forest: Higher accuracy for complex patterns"]},{"cell_type":"markdown","source":["Importing Necessary Libraries and Loading the Merged Dataset for Feature Engineering and Predictive Modeling."],"metadata":{"id":"zOMayhbLeiN-"}},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f81d684fd3564701aece01612163f02a","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":669,"execution_start":1738246404077,"source_hash":"f4bfa479","trusted":false,"id":"gXWd75ziaukE"},"outputs":[],"source":["#Loading libraries\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","\n","# Load the merged dataset\n","merged_data = pd.read_csv(\"merged_data.csv\")"]},{"cell_type":"markdown","metadata":{"id":"65bc8a6d"},"source":["Handling Missing Data: Imputation for Numerical, Categorical, and Date Columns"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"f382306cc9bf4c47a3304ca15357e157","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":1,"execution_start":1738246431876,"source_hash":"549ae03","trusted":false,"id":"fqIvPPo6aukH","outputId":"2d8c15bc-991c-40ca-bfe0-771b64f4874f"},"outputs":[{"name":"stderr","output_type":"stream","text":"C:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_26976\\710803340.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  merged_data[col].fillna(merged_data[col].median(), inplace=True)\nC:\\Users\\Acer\\AppData\\Local\\Temp\\ipykernel_26976\\710803340.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  merged_data[col].fillna(merged_data[col].median(), inplace=True)\n"}],"source":["#Feature Engineering#\n","# 1. Address Missing Data\n","# Numerical columns: Continuous and Count Data\n","numerical_columns = merged_data.select_dtypes(include=['float64', 'int64']).columns\n","for col in numerical_columns:\n","    if merged_data[col].isnull().sum() > 0:\n","        # Use median for imputation\n","        merged_data[col].fillna(merged_data[col].median(), inplace=True)\n","\n","# Categorical columns: Impute with the mode\n","categorical_columns = merged_data.select_dtypes(include=['object']).columns\n","for col in categorical_columns:\n","    if merged_data[col].isnull().sum() > 0:\n","        # Use mode for imputation\n","        merged_data[col].fillna(merged_data[col].mode()[0], inplace=True)\n","\n","# Date columns: Forward-fill or backward-fill for imputation\n","date_columns = [col for col in merged_data.columns if 'Date' in col or 'date' in col]\n","for col in date_columns:\n","    if merged_data[col].isnull().sum() > 0:\n","        # Forward-fill method\n","        merged_data[col] = pd.to_datetime(merged_data[col], errors='coerce')\n","        merged_data[col].fillna(method='ffill', inplace=True)"]},{"cell_type":"markdown","source":["One-Hot Encoding for Categorical Variables: Transforming Categorical Data into Numerical Format"],"metadata":{"id":"Z0PKX7Fge0fm"}},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8f2c494c7dc341b2b4bc2ca0e9e21196","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":0,"execution_start":1738246482497,"source_hash":"efa029b3","trusted":false,"id":"CRtnqCFHaukJ","outputId":"dca7c7e5-4443-48d7-8e56-d7a69d0023e1"},"outputs":[{"name":"stdout","output_type":"stream","text":"Available columns: Index(['Transaction_ID', 'Company_ID', 'Product_ID', 'Quantity',\n       'Transaction_Date', 'Product_Price_x', 'Total_Cost', 'Product_Name',\n       'Product_Price_y', 'Company_Name', 'Company_Profit', 'Address'],\n      dtype='object')\n"},{"ename":"TypeError","evalue":"OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[3], line 16\u001b[0m\n\u001b[0;32m      9\u001b[0m categorical_columns_to_encode \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     10\u001b[0m     col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m specified_categorical_columns \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m merged_data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m     11\u001b[0m ]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m categorical_columns_to_encode:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Update: Correcting the OneHotEncoder usage by removing the 'sparse_output' argument\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# which is not valid. This behavior is controlled by 'sparse' argument. Switching accordingly.\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     encoded_features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m     18\u001b[0m         encoder\u001b[38;5;241m.\u001b[39mfit_transform(merged_data[categorical_columns_to_encode]),\n\u001b[0;32m     19\u001b[0m         columns\u001b[38;5;241m=\u001b[39mencoder\u001b[38;5;241m.\u001b[39mget_feature_names_out(categorical_columns_to_encode)\n\u001b[0;32m     20\u001b[0m     )\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Add encoded features to the dataset\u001b[39;00m\n","\u001b[1;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"]}],"source":["# 2. One-Hot Encoding for Categorical Columns\n","# Verify available columns\n","print(\"Available columns:\", merged_data.columns)\n","\n","# Specify columns to encode (adjust if needed)\n","specified_categorical_columns = ['Product_Name', 'Company_Name', 'Address']\n","\n","# Dynamically filter to include only existing columns\n","categorical_columns_to_encode = [\n","    col for col in specified_categorical_columns if col in merged_data.columns\n","]\n","\n","if categorical_columns_to_encode:\n","    # Update: Correcting the OneHotEncoder usage by removing the 'sparse_output' argument\n","    # which is not valid. This behavior is controlled by 'sparse' argument. Switching accordingly.\n","    encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n","    encoded_features = pd.DataFrame(\n","        encoder.fit_transform(merged_data[categorical_columns_to_encode]),\n","        columns=encoder.get_feature_names_out(categorical_columns_to_encode)\n","    )\n","\n","    # Add encoded features to the dataset\n","    merged_data = pd.concat([merged_data.reset_index(drop=True), encoded_features.reset_index(drop=True)], axis=1)\n","\n","    # Drop original categorical columns after encoding\n","    merged_data = merged_data.drop(columns=categorical_columns_to_encode)\n","else:\n","    print(\"No valid categorical columns found for one-hot encoding.\")"]},{"cell_type":"markdown","source":["Scaling Numerical Features: Standardizing Continuous Variables for Modeling"],"metadata":{"id":"E7ByecFBe6bG"}},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"55edbb492978409482a2023fe464a841","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":1,"execution_start":1738246508584,"source_hash":"19e4809","trusted":false,"id":"9FCbhrHiaukK","outputId":"7acb266c-8639-421b-f6d0-19f340ea30be"},"outputs":[{"name":"stdout","output_type":"stream","text":"Feature Engineering Complete. Dataset Preview:\n   Transaction_ID  Company_ID  Product_ID  Quantity Transaction_Date  \\\n0             1.0        88.0         6.0  0.076948       2024-03-26   \n1             2.0        29.0        19.0  0.984139       2024-07-09   \n2             3.0        28.0        18.0 -0.830243       2024-04-13   \n3             4.0        85.0        12.0  0.258386       2023-09-06   \n4             5.0        47.0         3.0 -0.467367       2021-07-06   \n\n   Product_Price_x  Total_Cost            Product_Name  Product_Price_y  \\\n0    194379.147964   -0.395485    RevenueVue Dashboard         179200.0   \n1     97930.993380    0.013660        EcoNomix Modeler          95200.0   \n2    126095.547778   -0.551349  DashSync Analytics Hub         134400.0   \n3    131600.000000   -0.473417        BudgetMaster Pro          84000.0   \n4     99575.609634   -0.824112    TrendWise Forecaster         100800.0   \n\n            Company_Name  Company_Profit  \\\n0    Elite Consulting 88       -0.013588   \n1    Sky  Industries  29       -0.596943   \n2     Global Holdings 28       -0.631825   \n3      Green Ventures 85        1.550027   \n4  Green  Industries  47       -1.881425   \n\n                                            Address  \n0           EDSA, Barangay 456, Taguig, Philippines  \n1             Edsa, brgy. 606, makati, philippines!  \n2     Katipunan Ave, Brgy. 303, Taguig, Philippines  \n3        EDSA, Barangay 707, Cebu City, Philippines  \n4  Taft Ave, Barangay 707, Mandaluyong, Philippines  \n"}],"source":["# 3. Scale Numerical Features\n","# Define numerical columns for scaling (ensure they exist)\n","numerical_columns = [\n","    col for col in ['Product_Price', 'Quantity', 'Total_Cost', 'Company_Profit']\n","    if col in merged_data.columns\n","]\n","\n","if numerical_columns:\n","    scaler = StandardScaler()\n","    merged_data[numerical_columns] = scaler.fit_transform(merged_data[numerical_columns])\n","else:\n","    print(\"No valid numerical columns found for scaling.\")\n","\n","# Final Check: Ensure all features are processed\n","print(\"Feature Engineering Complete. Dataset Preview:\")\n","print(merged_data.head())"]},{"cell_type":"markdown","source":["Defining Features and Target Variable, and Splitting Data for Training and Testing"],"metadata":{"id":"oWLMhv-NfAoe"}},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8189746f0e704900bd1fc5a20c7dc342","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":22,"execution_start":1738246530063,"source_hash":"1fd35f41","trusted":false,"id":"boQtUjXDaukL"},"outputs":[],"source":["# Define X (features) and y (target)\n","X = merged_data.drop(columns=['Product_ID'])\n","y = merged_data['Product_ID']\n","\n","# Convert target variable to categorical (if necessary)\n","y = y.astype(str)\n","\n","### Split Data ###\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","source":["Handling Non-Numerical Features and Implementing Multinomial Logistic Regression"],"metadata":{"id":"FEEM9tQwdDrm"}},{"cell_type":"markdown","source":["## Logistic Regression Implementation\n","- Multi-class classification setup\n","- Maximum iterations set to handle convergence\n","- Provides probability scores for each class\n","- Features standardized for optimal performance\n","- Interpretable coefficients for feature importance"],"metadata":{"id":"S-bApHshfRdm"}},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"b3987e2ae3ee4229ad7884abc0bc6c1f","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":83214,"execution_start":1738246566212,"source_hash":"4ffb66ee","trusted":false,"id":"nGXve2d2aukL","outputId":"b891cb99-a7e4-4a51-9389-fe06c0840b6f"},"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n  warnings.warn(\n"},{"name":"stdout","output_type":"stream","text":"Multinomial Logistic Regression Metrics:\nAccuracy: 0.143\n              precision    recall  f1-score   support\n\n         1.0       0.00      0.00      0.00        82\n        10.0       0.14      0.79      0.24       266\n        11.0       0.00      0.00      0.00        92\n        12.0       0.43      0.03      0.06        97\n        13.0       0.08      0.01      0.02        77\n        14.0       0.00      0.00      0.00        93\n        15.0       0.00      0.00      0.00        83\n        16.0       0.00      0.00      0.00       106\n        17.0       0.00      0.00      0.00        82\n        18.0       0.00      0.00      0.00        96\n        19.0       0.00      0.00      0.00        85\n         2.0       0.00      0.00      0.00        88\n        20.0       0.14      0.70      0.23        90\n         3.0       0.00      0.00      0.00        98\n         4.0       0.00      0.00      0.00        94\n         5.0       0.25      0.08      0.12        97\n         6.0       0.00      0.00      0.00       100\n         7.0       0.00      0.00      0.00        93\n         8.0       0.00      0.00      0.00        86\n         9.0       0.00      0.00      0.00        95\n\n    accuracy                           0.14      2000\n   macro avg       0.05      0.08      0.03      2000\nweighted avg       0.06      0.14      0.05      2000\n\n"},{"name":"stderr","output_type":"stream","text":"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\nc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\nc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\nc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\nc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\nc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\nc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"}],"source":["# Fix: Remove or encode non-numerical columns in the features\n","# Drop non-numerical columns such as 'Transaction_Date' to avoid conversion errors\n","X_numerical = X.select_dtypes(include=['number'])\n","\n","# Split Data (again) after correction\n","X_train, X_test, y_train, y_test = train_test_split(X_numerical, y, test_size=0.2, random_state=42)\n","\n","# Model 1: Multinomial Logistic Regression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","# Multinomial Logistic Regression\n","logistic_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42, max_iter=1000)\n","\n","# Train the model\n","logistic_model.fit(X_train, y_train)\n","\n","# Predictions\n","y_pred_logistic = logistic_model.predict(X_test)\n","\n","# Evaluation Metrics\n","logistic_metrics = {\n","    \"Model\": \"Multinomial Logistic Regression\",\n","    \"Accuracy\": accuracy_score(y_test, y_pred_logistic),\n","    \"Classification Report\": classification_report(y_test, y_pred_logistic, output_dict=True)\n","}\n","\n","# Print results\n","print(\"Multinomial Logistic Regression Metrics:\")\n","print(f\"Accuracy: {logistic_metrics['Accuracy']}\")\n","print(classification_report(y_test, y_pred_logistic))\n","\n","# Save predictions to a DataFrame\n","logistic_predictions = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_logistic})\n","logistic_predictions.to_csv(\"logistic_predictions.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"60ea2e13"},"source":["Implementing and Evaluating Random Forest Classifier"]},{"cell_type":"markdown","source":["## Random Forest Implementation\n","- 100 decision trees (n_estimators=100)\n","- Random state set for reproducibility\n","- Automatic feature importance calculation\n","- Handles both numerical and categorical features\n","- Robust to outliers and noise in data"],"metadata":{"id":"DqnTICBVfdQ1"}},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"bf460760d9814f93855fbae279558e2c","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":1182,"execution_start":1738246676468,"source_hash":"b67e682","trusted":false,"id":"4AHJ4YjfaukN","outputId":"98e577ef-1611-49e0-8f8b-10ad8e95d03f"},"outputs":[{"name":"stdout","output_type":"stream","text":"Random Forest Classifier Metrics:\nAccuracy: 0.8015\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00        82\n        10.0       0.91      0.93      0.92       266\n        11.0       1.00      1.00      1.00        92\n        12.0       0.51      0.52      0.51        97\n        13.0       1.00      1.00      1.00        77\n        14.0       1.00      1.00      1.00        93\n        15.0       0.49      0.51      0.50        83\n        16.0       0.99      1.00      1.00       106\n        17.0       0.49      0.49      0.49        82\n        18.0       0.79      0.76      0.78        96\n        19.0       1.00      1.00      1.00        85\n         2.0       0.53      0.53      0.53        88\n        20.0       1.00      1.00      1.00        90\n         3.0       0.56      0.54      0.55        98\n         4.0       1.00      1.00      1.00        94\n         5.0       0.51      0.49      0.50        97\n         6.0       1.00      1.00      1.00       100\n         7.0       0.52      0.47      0.50        93\n         8.0       0.48      0.53      0.51        86\n         9.0       1.00      0.99      0.99        95\n\n    accuracy                           0.80      2000\n   macro avg       0.79      0.79      0.79      2000\nweighted avg       0.80      0.80      0.80      2000\n\n"}],"source":["#Model 2: Random Forest Classifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Random Forest Classifier\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","\n","# Train the model\n","rf_model.fit(X_train, y_train)\n","\n","# Predictions\n","y_pred_rf = rf_model.predict(X_test)\n","\n","# Evaluation Metrics\n","rf_metrics = {\n","    \"Model\": \"Random Forest Classifier\",\n","    \"Accuracy\": accuracy_score(y_test, y_pred_rf),\n","    \"Classification Report\": classification_report(y_test, y_pred_rf, output_dict=True)\n","}\n","\n","# Print results\n","print(\"Random Forest Classifier Metrics:\")\n","print(f\"Accuracy: {rf_metrics['Accuracy']}\")\n","print(classification_report(y_test, y_pred_rf))\n","\n","# Save predictions to a DataFrame\n","rf_predictions = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred_rf})\n","rf_predictions.to_csv(\"rf_predictions.csv\", index=False)"]},{"cell_type":"markdown","metadata":{"id":"bcf55ba1"},"source":["Model Performance Comparison: Evaluating Logistic Regression and Random Forest Classifier"]},{"cell_type":"markdown","source":["## Model Evaluation Strategy\n","### Metrics Used and Why:\n","1. Accuracy\n","   - Measures overall prediction correctness\n","   - Easy to communicate to stakeholders\n","   - Baseline performance indicator\n","\n","2. Precision\n","   - Important for minimizing false positives\n","   - Critical for resource allocation decisions\n","   - Measures prediction reliability\n","\n","3. Recall\n","   - Captures ability to find all positive cases\n","   - Important for not missing opportunities\n","   - Key for comprehensive coverage\n","\n","4. F1-Score\n","   - Balances precision and recall\n","   - Single metric for model comparison\n","   - Handles class imbalance"],"metadata":{"id":"-31sIzlAfufm"}},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"52fec72b3f134dfb883adda2f65d00d9","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":163,"execution_start":1738246705280,"source_hash":"e4cdd076","trusted":false,"id":"OU_zEJJ2aukN","outputId":"5bbb9065-a5a0-45a7-98c8-22b8c6b704cb"},"outputs":[{"name":"stdout","output_type":"stream","text":"Model Comparison Table:\n                             Model  Accuracy  Precision (Weighted Avg)  \\\n0  Multinomial Logistic Regression    0.1430                  0.061358   \n1         Random Forest Classifier    0.8015                  0.801369   \n\n   Recall (Weighted Avg)  F1-Score (Weighted Avg)  \n0                 0.1430                 0.052301  \n1                 0.8015                 0.801266  \n"}],"source":["#Model Comparison Matrix\n","# Consolidate metrics into a single table\n","comparison_table = pd.DataFrame({\n","    \"Model\": [logistic_metrics[\"Model\"], rf_metrics[\"Model\"]],\n","    \"Accuracy\": [logistic_metrics[\"Accuracy\"], rf_metrics[\"Accuracy\"]],\n","    \"Precision (Weighted Avg)\": [\n","        logistic_metrics[\"Classification Report\"][\"weighted avg\"][\"precision\"],\n","        rf_metrics[\"Classification Report\"][\"weighted avg\"][\"precision\"]\n","    ],\n","    \"Recall (Weighted Avg)\": [\n","        logistic_metrics[\"Classification Report\"][\"weighted avg\"][\"recall\"],\n","        rf_metrics[\"Classification Report\"][\"weighted avg\"][\"recall\"]\n","    ],\n","    \"F1-Score (Weighted Avg)\": [\n","        logistic_metrics[\"Classification Report\"][\"weighted avg\"][\"f1-score\"],\n","        rf_metrics[\"Classification Report\"][\"weighted avg\"][\"f1-score\"]\n","    ]\n","})\n","\n","# Save comparison table to CSV\n","comparison_table.to_csv(\"model_comparison.csv\", index=False)\n","\n","# Print the comparison table\n","print(\"Model Comparison Table:\")\n","print(comparison_table)"]},{"cell_type":"markdown","metadata":{"id":"1e7c90c3"},"source":["Side-by-Side Prediction Comparison: Logistic Regression vs. Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"53eed1d6d1194ad9abeed6f1508c1c2b","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":1,"execution_start":1738246738052,"source_hash":"66da47f9","trusted":false,"id":"YwG38el4aukO","outputId":"a1a45c2a-f935-4b0b-afe7-e0c93d1e9158"},"outputs":[{"name":"stdout","output_type":"stream","text":"\nComparison of Predictions Side by Side:\n    Sample Index Actual Logistic Regression Prediction  \\\n0           6252   19.0                           10.0   \n1           4684   10.0                           10.0   \n2           1731   10.0                           10.0   \n3           4742    3.0                           10.0   \n4           4521    3.0                           10.0   \n5           6340    9.0                           20.0   \n6            576   17.0                            6.0   \n7           5202    3.0                           10.0   \n8           6363   14.0                           10.0   \n9            439    9.0                           20.0   \n10          2750    1.0                           10.0   \n11          7487    3.0                           10.0   \n\n   Random Forest Prediction  \n0                      19.0  \n1                      10.0  \n2                      18.0  \n3                       3.0  \n4                      15.0  \n5                       9.0  \n6                       2.0  \n7                      15.0  \n8                      14.0  \n9                       9.0  \n10                      1.0  \n11                     15.0  \n"}],"source":["# Predict on the same sample data\n","sample_data = X_test.iloc[:12]  # Predicting 12 datapoints\n","logistic_predictions = logistic_model.predict(sample_data)\n","rf_predictions = rf_model.predict(sample_data)\n","\n","# Combine predictions into a single DataFrame\n","comparison_df = pd.DataFrame({\n","    'Sample Index': sample_data.index,\n","    'Actual': y_test.loc[sample_data.index].values,\n","    'Logistic Regression Prediction': logistic_predictions,\n","    'Random Forest Prediction': rf_predictions\n","})\n","\n","# Display the comparison table\n","print(\"\\nComparison of Predictions Side by Side:\")\n","print(comparison_df)"]},{"cell_type":"markdown","source":["Comparing Predicted Probabilities and Performance of Logistic Regression vs. Random Forest"],"metadata":{"id":"9QGW4oZHf_W-"}},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"268ddf2fa8064547b54a4b4176ddeb7a","deepnote_cell_type":"code","execution_context_id":"f67a6328-c7e9-4f19-b34c-113f3cdbc209","execution_millis":383,"execution_start":1738246806796,"source_hash":"a796ef5","trusted":false,"id":"2GNJ3pTBaukP","outputId":"fbadfd13-8f8a-4556-bb91-7ad353d9069b"},"outputs":[{"name":"stdout","output_type":"stream","text":"\nPredicted Probabilities from Both Models (Logistic Regression vs Random Forest):\n     Logistic Regression                                                    \\\n               Product_1 Product_2 Product_3 Product_4 Product_5 Product_6   \n0               0.055181  0.094298  0.044384  0.041486  0.039665  0.043985   \n1               0.058622  0.175505  0.061454  0.015255  0.050084  0.049743   \n2               0.054494  0.206480  0.071431  0.010983  0.046753  0.055479   \n3               0.055026  0.100695  0.051357  0.031429  0.043363  0.047297   \n4               0.046622  0.123365  0.040585  0.049782  0.021819  0.046903   \n...                  ...       ...       ...       ...       ...       ...   \n1995            0.043241  0.090009  0.031813  0.068389  0.018976  0.039453   \n1996            0.060423  0.155658  0.057386  0.012026  0.058520  0.041438   \n1997            0.024687  0.176034  0.012659  0.132185  0.003059  0.027880   \n1998            0.051149  0.055699  0.069459  0.009144  0.100122  0.042573   \n1999            0.045420  0.093273  0.033010  0.064406  0.021025  0.039673   \n\n                                               ... Random Forest             \\\n     Product_7 Product_8 Product_9 Product_10  ...    Product_11 Product_12   \n0     0.050163  0.051998  0.049854   0.050679  ...          0.84       0.00   \n1     0.029129  0.033365  0.056440   0.051961  ...          0.00       0.00   \n2     0.027020  0.029545  0.058104   0.049761  ...          0.00       0.00   \n3     0.047075  0.048527  0.055739   0.050445  ...          0.00       0.00   \n4     0.065786  0.057720  0.040823   0.046085  ...          0.10       0.00   \n...        ...       ...       ...        ...  ...           ...        ...   \n1995  0.073741  0.063818  0.036128   0.042441  ...          0.46       0.00   \n1996  0.026841  0.032927  0.064754   0.049139  ...          0.00       0.05   \n1997  0.072745  0.050892  0.009681   0.028528  ...          0.04       0.00   \n1998  0.021121  0.026470  0.076422   0.043478  ...          0.00       0.00   \n1999  0.070376  0.062832  0.037998   0.043868  ...          0.15       0.00   \n\n                                                                        \\\n     Product_13 Product_14 Product_15 Product_16 Product_17 Product_18   \n0           0.0       0.03       0.00       0.00       0.00        0.0   \n1           0.0       0.01       0.03       0.00       0.00        0.0   \n2           0.0       0.00       0.03       0.00       0.00        0.0   \n3           0.0       0.59       0.00       0.00       0.00        0.0   \n4           0.0       0.26       0.00       0.02       0.00        0.0   \n...         ...        ...        ...        ...        ...        ...   \n1995        0.0       0.09       0.02       0.07       0.00        0.0   \n1996        0.0       0.00       0.00       0.00       0.87        0.0   \n1997        0.0       0.01       0.00       0.00       0.00        0.0   \n1998        0.0       0.00       0.00       0.50       0.00        0.0   \n1999        0.0       0.32       0.01       0.02       0.00        0.0   \n\n                            \n     Product_19 Product_20  \n0           0.0       0.00  \n1           0.0       0.16  \n2           0.0       0.00  \n3           0.0       0.01  \n4           0.0       0.03  \n...         ...        ...  \n1995        0.0       0.05  \n1996        0.0       0.00  \n1997        0.0       0.00  \n1998        0.0       0.00  \n1999        0.0       0.06  \n\n[2000 rows x 40 columns]\n\nLogistic Regression Accuracy: 0.1430\nRandom Forest Accuracy: 0.8015\n\nLogistic Regression Classification Report:\n              precision    recall  f1-score   support\n\n         1.0       0.00      0.00      0.00        82\n        10.0       0.14      0.79      0.24       266\n        11.0       0.00      0.00      0.00        92\n        12.0       0.43      0.03      0.06        97\n        13.0       0.08      0.01      0.02        77\n        14.0       0.00      0.00      0.00        93\n        15.0       0.00      0.00      0.00        83\n        16.0       0.00      0.00      0.00       106\n        17.0       0.00      0.00      0.00        82\n        18.0       0.00      0.00      0.00        96\n        19.0       0.00      0.00      0.00        85\n         2.0       0.00      0.00      0.00        88\n        20.0       0.14      0.70      0.23        90\n         3.0       0.00      0.00      0.00        98\n         4.0       0.00      0.00      0.00        94\n         5.0       0.25      0.08      0.12        97\n         6.0       0.00      0.00      0.00       100\n         7.0       0.00      0.00      0.00        93\n         8.0       0.00      0.00      0.00        86\n         9.0       0.00      0.00      0.00        95\n\n    accuracy                           0.14      2000\n   macro avg       0.05      0.08      0.03      2000\nweighted avg       0.06      0.14      0.05      2000\n\n\nRandom Forest Classification Report:\n              precision    recall  f1-score   support\n\n         1.0       1.00      1.00      1.00        82\n        10.0       0.91      0.93      0.92       266\n        11.0       1.00      1.00      1.00        92\n        12.0       0.51      0.52      0.51        97\n        13.0       1.00      1.00      1.00        77\n        14.0       1.00      1.00      1.00        93\n        15.0       0.49      0.51      0.50        83\n        16.0       0.99      1.00      1.00       106\n        17.0       0.49      0.49      0.49        82\n        18.0       0.79      0.76      0.78        96\n        19.0       1.00      1.00      1.00        85\n         2.0       0.53      0.53      0.53        88\n        20.0       1.00      1.00      1.00        90\n         3.0       0.56      0.54      0.55        98\n         4.0       1.00      1.00      1.00        94\n         5.0       0.51      0.49      0.50        97\n         6.0       1.00      1.00      1.00       100\n         7.0       0.52      0.47      0.50        93\n         8.0       0.48      0.53      0.51        86\n         9.0       1.00      0.99      0.99        95\n\n    accuracy                           0.80      2000\n   macro avg       0.79      0.79      0.79      2000\nweighted avg       0.80      0.80      0.80      2000\n\n"},{"name":"stderr","output_type":"stream","text":"c:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\nc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\nc:\\Users\\Acer\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"}],"source":["from sklearn.metrics import accuracy_score, classification_report\n","\n","# Correctly reference the RandomForestClassifier object defined previously\n","rf_pred_probs = rf_model.predict_proba(X_test)  # Changed 'random_forest_model' to 'rf_model'\n","\n","# --- Printing the predictions side by side ---\n","# Create a DataFrame for the predictions to print them side by side\n","logistic_pred_df = pd.DataFrame(logistic_model.predict_proba(X_test), columns=[f'Product_{i}' for i in range(1, len(logistic_model.classes_) + 1)])  # Fixed logistic_pred_probs\n","rf_pred_df = pd.DataFrame(rf_pred_probs, columns=[f'Product_{i}' for i in range(1, len(rf_model.classes_) + 1)])\n","\n","# Print the predicted probabilities from both models side by side\n","comparison_df = pd.concat([logistic_pred_df, rf_pred_df], axis=1, keys=[\"Logistic Regression\", \"Random Forest\"])\n","print(\"\\nPredicted Probabilities from Both Models (Logistic Regression vs Random Forest):\")\n","print(comparison_df)\n","\n","# --- Accuracy and Metrics ---\n","# Predict classes for evaluation (select the product with the highest probability)\n","logistic_preds = logistic_model.predict(X_test)\n","rf_preds = rf_model.predict(X_test)  # Changed 'random_forest_model' to 'rf_model'\n","\n","# Calculate accuracy scores\n","logistic_accuracy = accuracy_score(y_test, logistic_preds)\n","rf_accuracy = accuracy_score(y_test, rf_preds)\n","\n","print(f\"\\nLogistic Regression Accuracy: {logistic_accuracy:.4f}\")\n","print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n","\n","# --- Display Classification Reports ---\n","print(\"\\nLogistic Regression Classification Report:\")\n","print(classification_report(y_test, logistic_preds))\n","\n","print(\"\\nRandom Forest Classification Report:\")\n","print(classification_report(y_test, rf_preds))"]},{"cell_type":"markdown","source":["**Conclusion and Rationale**\n","\n","Based on the evaluation metrics, the Random Forest Classifier significantly outperforms Multinomial Logistic Regression in terms of accuracy, precision, recall, and F1-score.\n","\n","1. Multinomial Logistic Regression performs poorly with an accuracy of 14.3%, a low precision of 6.1%, and an F1-score of 5.2%, indicating that the model struggles to correctly classify the data. This suggests that the data may not follow a linear decision boundary, making logistic regression unsuitable for this problem.\n","\n","2. Random Forest Classifier, on the other hand, achieves an accuracy of 80.15%, with consistently high precision, recall, and F1-score (~80.1%). This suggests that the model effectively captures patterns in the dataset, likely benefiting from its ensemble learning approach, which reduces variance and improves classification performance.\n","\n","**Rationale:**\n","\n","1. Model Suitability: The poor performance of logistic regression suggests that the problem is highly nonlinear, making tree-based methods like Random Forest more effective.\n","\n","2. Feature Importance: Random Forest can capture complex relationships and interactions between features, whereas logistic regression assumes a linear relationship, which may not exist in the data.\n","\n","3. Overfitting Concern: While 80.15% accuracy is strong, further validation is needed to ensure the Random Forest model is not overfitting, especially if the training accuracy is significantly higher. Cross-validation and hyperparameter tuning should be performed to confirm its robustness.\n","\n","Next Steps: If overfitting is suspected, techniques such as feature selection, hyperparameter tuning, or testing alternative models (e.g., Gradient Boosting, XGBoost) should be explored."],"metadata":{"id":"4YJZgQX-bIF1"}},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown","id":"QxtPPDstaukP"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=6a672b84-99aa-4a43-8d4f-014dc3397bc0' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote_notebook_id":"08ebbbf5eb134fc8842cabe25be9fce0","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}